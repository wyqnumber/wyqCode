
spark集群上如何配置深度学习elephas框架的操作流程
http://blog.csdn.net/richard_more/article/details/53420812
这篇文章中的代码能够运行，要求 keras的版本很低。
pip install elephas　　pip install keras==0.3.0

运行时，出现错误：WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory

原因：
host配置不正确
worker内存不足
相关端口号被占用

解决：
可能是内存不足，减少数据到60条就可以了。
还有加内存，参考 http://blog.csdn.net/qyl445/article/details/50684691
命令行中的内存大小，不能大于配置文件中的内存大小。


这篇文章直接在docker配置spark，代码跑不了
http://blog.csdn.net/cyh_24/article/details/49683221
可以看评论：
model.add(Convolution2D(nb_filters, nb_conv, nb_conv,
border_mode='full',
input_shape=(1, img_rows, img_cols)))
可能需要修改为
model.add(Convolution2D(nb_filters, nb_conv, nb_conv,
border_mode='valid',
input_shape=(1, img_rows, img_cols)))

elephas好像没有num_workers这个参数
